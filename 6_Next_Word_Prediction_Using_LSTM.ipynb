{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Greeshmasindhu24/Next-Word-Prediction-Using--LSTM/blob/main/6_Next_Word_Prediction_Using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4_-ENCyo9Z-",
        "outputId": "fa164f4d-e561-4540-a4bd-df48fb1d66c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0305 - loss: 6.5746\n",
            "Epoch 2/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0448 - loss: 5.7016\n",
            "Epoch 3/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0623 - loss: 5.6055\n",
            "Epoch 4/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0716 - loss: 5.3997\n",
            "Epoch 5/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0775 - loss: 5.3325\n",
            "Epoch 6/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0913 - loss: 5.1767\n",
            "Epoch 7/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1029 - loss: 5.0163\n",
            "Epoch 8/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1212 - loss: 4.8642\n",
            "Epoch 9/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1340 - loss: 4.6740\n",
            "Epoch 10/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1588 - loss: 4.4915\n",
            "\n",
            "✅ Next-word prediction accuracy: 0.1787\n",
            "\n",
            "Enter your sentence (or 'q' to quit): the power bi is used for\n",
            "\n",
            "Predicted next word: 'data'\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import fitz\n",
        "\n",
        "# Load and clean data\n",
        "doc = fitz.open('/content/drive/MyDrive/Hands on/power-bi-question.pdf')\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text().lower()  # Extract text from each page\n",
        "\n",
        "text = re.sub('[^a-z\\s]', '', text)  # Remove everything except lowercase letters and spaces\n",
        "words = text.split()\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Prepare sequences\n",
        "max_len = 5\n",
        "X, y = [], []\n",
        "for i in range(max_len, len(words)):\n",
        "    context = ' '.join(words[i-max_len:i])\n",
        "    X.append(context)\n",
        "    y.append(words[i])\n",
        "\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_len, padding='post')\n",
        "y_labels = [tokenizer.word_index[word] for word in y]\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, 64, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_pad, np.array(y_labels), epochs=10, batch_size=32)\n",
        "\n",
        "# ✅ Accuracy calculation (manual word prediction accuracy)\n",
        "correct = 0\n",
        "total = len(X_pad)\n",
        "\n",
        "for i in range(total):\n",
        "    input_seq = X_pad[i].reshape(1, -1)\n",
        "    true_label = y_labels[i]\n",
        "    pred_probs = model.predict(input_seq, verbose=0)[0]\n",
        "    pred_label = np.argmax(pred_probs)\n",
        "    if pred_label == true_label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"\\n✅ Next-word prediction accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_word(sentence, top_k=3):\n",
        "    words = sentence.lower().split()[-max_len:]\n",
        "    seq = tokenizer.texts_to_sequences([' '.join(words)])[0]\n",
        "    padded = pad_sequences([seq], maxlen=max_len, padding='post')\n",
        "    probs = model.predict(padded, verbose=0)[0]\n",
        "    top_indices = np.argsort(probs)[-top_k:]\n",
        "    return tokenizer.index_word[np.random.choice(top_indices)]\n",
        "\n",
        "# Interactive prediction\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter your sentence (or 'q' to quit): \").strip()\n",
        "    if user_input.lower() == 'q':\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "    if not user_input:\n",
        "        print(\"Error: Please type a sentence.\")\n",
        "        continue\n",
        "\n",
        "    predicted_word = predict_word(user_input)\n",
        "    print(f\"\\nPredicted next word: '{predicted_word}'\")\n",
        "\n",
        "# Test prediction\n",
        "print(\"\\nTest prediction for: 'power bi is used for'\")\n",
        "print(\"Predicted word:\", predict_word(\"power bi is used for\"))\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PEuQiwlvaviE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tvhl-YYGEuqAEubDgjIKH91PkIl9fTsg",
      "authorship_tag": "ABX9TyMaFKNfZQpU1jnMLNGfUA4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}